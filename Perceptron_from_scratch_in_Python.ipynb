{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNVTwzfPo43qEW1wqxeZG56",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GithubPython7Eduard/Python-Library/blob/main/Perceptron_from_scratch_in_Python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3UHYKidOWUX"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sigmoid Perceptron Class"
      ],
      "metadata": {
        "id": "hNNn_VxfOoRy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SigmoidPerceptron():\n",
        "  def __init__(self, input_size):\n",
        "\n",
        "    self.weights = np.random.randn(input_size)\n",
        "    self.buas = np.random.randn(1)\n",
        "\n",
        "\n",
        "  def sigmoid(self, z):\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "\n",
        "  # input_size  -->  [10, 25, 50]; weights  -->  [0.5, 0.9, 0.1]\n",
        "\n",
        "  def predict(self, inputs):\n",
        "    weighted_sum = np.dot(inputs, self.weights) + self.bias   # (10*0.5) + (25*0.9) + (50*0.1) + b(0.56)\n",
        "    return self.sigmoid(weighted_sum)\n",
        "\n",
        "\n",
        "  # optimize the model\n",
        "  def fit(self, inputs, targets, learning_rate, num_epochs):   # 100\n",
        "\n",
        "    num_examples = inputs.shape[0]   # 1000\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "      for i in range(num_examples):\n",
        "\n",
        "        input_vector = inputs[i]\n",
        "        target = targets[i]\n",
        "        # predict function is above  -->  inputs the same as input_vector\n",
        "        prediction = self.predict(input_vector)\n",
        "\n",
        "        # difference between target\n",
        "        error = target - prediction\n",
        "\n",
        "        # w  =  w  -  L * dw\n",
        "        # update weights\n",
        "        gradient_weights = error * prediction * (1 - prediction) * input_vector\n",
        "        self.weights += learning_rate * gradient_weights\n",
        "\n",
        "        # b  =  b  -  L * db\n",
        "        # update bias\n",
        "        gradient_bias = error * prediction * (1 - prediction)\n",
        "        self.bias += learning_rate * gradient_bias\n",
        "\n",
        "\n",
        "  # passing inputs & targets values\n",
        "  # X_test  -->  inputs |  Y_test  -->  targets\n",
        "  def evaluate(self, inputs, targets):\n",
        "    # correct --> using as a counter correct my model predicted values\n",
        "    correct = 0\n",
        "\n",
        "    for input_vector, target in zip(inputs, targets):\n",
        "      # passing data inputs to input vector\n",
        "      prediction = self.predict(input_vector)\n",
        "\n",
        "      if prediction >= 0.5:\n",
        "        predicted_class = 1\n",
        "\n",
        "      else:predicted_class = 0\n",
        "\n",
        "      if predicted_class == target:\n",
        "        correct += 1\n",
        "\n",
        "      # accuracy = number of correct prediction / total of number datapoints\n",
        "      accuracy = correct / len(inputs)\n",
        "      return accuracy"
      ],
      "metadata": {
        "id": "fFNhGpwTOmzd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}